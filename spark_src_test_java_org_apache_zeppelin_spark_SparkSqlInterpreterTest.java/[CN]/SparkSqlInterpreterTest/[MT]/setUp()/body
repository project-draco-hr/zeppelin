{
  Properties p=new Properties();
  p.putAll(SparkInterpreterTest.getSparkTestProperties());
  p.setProperty("zeppelin.spark.maxResult","1000");
  p.setProperty("zeppelin.spark.concurrentSQL","false");
  p.setProperty("zeppelin.spark.sql.stacktrace","false");
  if (repl == null) {
    if (SparkInterpreterTest.repl == null) {
      repl=new SparkInterpreter(p);
      intpGroup=new InterpreterGroup();
      repl.setInterpreterGroup(intpGroup);
      repl.open();
      SparkInterpreterTest.repl=repl;
      SparkInterpreterTest.intpGroup=intpGroup;
    }
 else {
      repl=SparkInterpreterTest.repl;
      intpGroup=SparkInterpreterTest.intpGroup;
    }
    sql=new SparkSqlInterpreter(p);
    intpGroup=new InterpreterGroup();
    intpGroup.put("note",new LinkedList<Interpreter>());
    intpGroup.get("note").add(repl);
    intpGroup.get("note").add(sql);
    sql.setInterpreterGroup(intpGroup);
    sql.open();
  }
  context=new InterpreterContext("note","id","title","text",new AuthenticationInfo(),new HashMap<String,Object>(),new GUI(),new AngularObjectRegistry(intpGroup.getId(),null),new LocalResourcePool("id"),new LinkedList<InterpreterContextRunner>(),new InterpreterOutput(new InterpreterOutputListener(){
    @Override public void onAppend(    InterpreterOutput out,    byte[] line){
    }
    @Override public void onUpdate(    InterpreterOutput out,    byte[] output){
    }
  }
));
}
