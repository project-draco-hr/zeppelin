{
  Settings settings=new Settings();
  URL[] urls=getClassloaderUrls();
  PathSetting pathSettings=settings.classpath();
  String classpath="";
  List<File> paths=currentClassPath();
  for (  File f : paths) {
    if (classpath.length() > 0) {
      classpath+=File.pathSeparator;
    }
    classpath+=f.getAbsolutePath();
  }
  if (urls != null) {
    for (    URL u : urls) {
      if (classpath.length() > 0) {
        classpath+=File.pathSeparator;
      }
      classpath+=u.getFile();
    }
  }
  pathSettings.v_$eq(classpath);
  settings.scala$tools$nsc$settings$ScalaSettings$_setter_$classpath_$eq(pathSettings);
  settings.explicitParentLoader_$eq(new Some<ClassLoader>(Thread.currentThread().getContextClassLoader()));
  BooleanSetting b=(BooleanSetting)settings.usejavacp();
  b.v_$eq(true);
  settings.scala$tools$nsc$settings$StandardScalaSettings$_setter_$usejavacp_$eq(b);
  interpreter=new SparkILoop((java.io.BufferedReader)null,new PrintWriter(out));
  interpreter.settings_$eq(settings);
  interpreter.createInterpreter();
  intp=Utils.invokeMethod(interpreter,"intp");
  if (Utils.isScala2_10()) {
    Utils.invokeMethod(intp,"setContextClassLoader");
    Utils.invokeMethod(intp,"initializeSynchronous");
  }
  depc=new SparkDependencyContext(getProperty("zeppelin.dep.localrepo"),getProperty("zeppelin.dep.additionalRemoteRepository"));
  if (Utils.isScala2_10()) {
    completor=Utils.instantiateClass("org.apache.spark.repl.SparkJLineCompletion",new Class[]{Utils.findClass("org.apache.spark.repl.SparkIMain")},new Object[]{intp});
  }
  interpret("@transient var _binder = new java.util.HashMap[String, Object]()");
  Map<String,Object> binder;
  if (Utils.isScala2_10()) {
    binder=(Map<String,Object>)getValue("_binder");
  }
 else {
    binder=(Map<String,Object>)getLastObject();
  }
  binder.put("depc",depc);
  interpret("@transient val z = " + "_binder.get(\"depc\")" + ".asInstanceOf[org.apache.zeppelin.spark.dep.SparkDependencyContext]");
}
