{
  System.err.println("------ Create new SparkContext " + getProperty("master") + " -------");
  String execUri=System.getenv("SPARK_EXECUTOR_URI");
  String[] jars=SparkILoop.getAddedJars();
  SparkConf conf=new SparkConf().setMaster(getProperty("master")).setAppName(getProperty("spark.app.name")).setJars(jars).set("spark.repl.class.uri",interpreter.intp().classServer().uri());
  if (execUri != null) {
    conf.set("spark.executor.uri",execUri);
  }
  if (System.getenv("SPARK_HOME") != null) {
    conf.setSparkHome(System.getenv("SPARK_HOME"));
  }
  conf.set("spark.scheduler.mode","FAIR");
  Properties intpProperty=getProperty();
  for (  Object k : intpProperty.keySet()) {
    String key=(String)k;
    if (key.startsWith("spark.")) {
      Object value=intpProperty.get(k);
      if (value != null && value instanceof String && !((String)value).trim().isEmpty()) {
        conf.set(key,intpProperty.getProperty(key));
      }
    }
  }
  SparkContext sparkContext=new SparkContext(conf);
  return sparkContext;
}
