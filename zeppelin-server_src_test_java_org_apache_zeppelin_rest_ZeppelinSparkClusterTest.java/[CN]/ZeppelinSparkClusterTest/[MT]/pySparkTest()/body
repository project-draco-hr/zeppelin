{
  Note note=ZeppelinServer.notebook.createNote(null);
  note.setName("note");
  int sparkVersion=getSparkVersionNumber(note);
  if (isPyspark() && sparkVersion >= 12) {
    Paragraph p=note.addParagraph();
    Map config=p.getConfig();
    config.put("enabled",true);
    p.setConfig(config);
    p.setText("%pyspark print(sc.parallelize(range(1, 11)).reduce(lambda a, b: a + b))");
    note.run(p.getId());
    waitForFinish(p);
    assertEquals(Status.FINISHED,p.getStatus());
    assertEquals("55\n",p.getResult().message());
    if (sparkVersion >= 13) {
      p=note.addParagraph();
      config=p.getConfig();
      config.put("enabled",true);
      p.setConfig(config);
      p.setText("%pyspark from pyspark.sql import Row\n" + "df=sqlContext.createDataFrame([Row(id=1, age=20)])\n" + "df.collect()");
      note.run(p.getId());
      waitForFinish(p);
      assertEquals(Status.FINISHED,p.getStatus());
      assertEquals("[Row(age=20, id=1)]\n",p.getResult().message());
      p=note.addParagraph();
      config=p.getConfig();
      config.put("enabled",true);
      p.setConfig(config);
      p.setText("%pyspark from pyspark.sql import Row\n" + "df=sqlContext.createDataFrame([Row(id=1, age=20)])\n" + "z.show(df)");
      note.run(p.getId());
      waitForFinish(p);
      assertEquals(Status.FINISHED,p.getStatus());
      assertEquals(InterpreterResult.Type.TABLE,p.getResult().type());
      assertEquals("age\tid\n20\t1\n\n",p.getResult().message());
    }
    if (sparkVersion >= 20) {
      p=note.addParagraph();
      config=p.getConfig();
      config.put("enabled",true);
      p.setConfig(config);
      p.setText("%pyspark from pyspark.sql import Row\n" + "df=sqlContext.createDataFrame([Row(id=1, age=20)])\n" + "df.collect()");
      note.run(p.getId());
      waitForFinish(p);
      assertEquals(Status.FINISHED,p.getStatus());
      assertEquals("[Row(age=20, id=1)]\n",p.getResult().message());
    }
  }
  ZeppelinServer.notebook.removeNote(note.getId(),null);
}
