{
  logger.info("------ Create new SparkContext {} -------",getProperty("master"));
  String execUri=System.getenv("SPARK_EXECUTOR_URI");
  String[] jars=null;
  if (Utils.isScala2_10()) {
    jars=(String[])Utils.invokeStaticMethod(SparkILoop.class,"getAddedJars");
  }
 else {
    jars=(String[])Utils.invokeStaticMethod(Utils.findClass("org.apache.spark.repl.Main"),"getAddedJars");
  }
  String classServerUri=null;
  try {
    Method classServer=intp.getClass().getMethod("classServer");
    Object httpServer=classServer.invoke(intp);
    classServerUri=(String)Utils.invokeMethod(httpServer,"uri");
  }
 catch (  NoSuchMethodException|SecurityException|IllegalAccessException|IllegalArgumentException|InvocationTargetException e) {
  }
  if (classServerUri == null) {
    try {
      Method classServer=intp.getClass().getMethod("classServerUri");
      classServerUri=(String)classServer.invoke(intp);
    }
 catch (    NoSuchMethodException|SecurityException|IllegalAccessException|IllegalArgumentException|InvocationTargetException e) {
      logger.warn(String.format("Spark method classServerUri not available due to: [%s]",e.getMessage()));
    }
  }
  if (Utils.isScala2_11()) {
    classServer=createHttpServer(outputDir);
    Utils.invokeMethod(classServer,"start");
    classServerUri=(String)Utils.invokeMethod(classServer,"uri");
  }
  conf.setMaster(getProperty("master")).setAppName(getProperty("spark.app.name"));
  if (classServerUri != null) {
    conf.set("spark.repl.class.uri",classServerUri);
  }
  if (jars.length > 0) {
    conf.setJars(jars);
  }
  if (execUri != null) {
    conf.set("spark.executor.uri",execUri);
  }
  if (System.getenv("SPARK_HOME") != null) {
    conf.setSparkHome(System.getenv("SPARK_HOME"));
  }
  conf.set("spark.scheduler.mode","FAIR");
  Properties intpProperty=getProperty();
  for (  Object k : intpProperty.keySet()) {
    String key=(String)k;
    String val=toString(intpProperty.get(key));
    if (!key.startsWith("spark.") || !val.trim().isEmpty()) {
      logger.debug(String.format("SparkConf: key = [%s], value = [%s]",key,val));
      conf.set(key,val);
    }
  }
  setupConfForPySpark(conf);
  SparkContext sparkContext=new SparkContext(conf);
  return sparkContext;
}
